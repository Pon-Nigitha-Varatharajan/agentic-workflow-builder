â¸»

âš¡ Agentic Workflow Builder

A full-stack Agentic Workflow Builder that lets users design, execute, and monitor multi-step AI workflows using LLMs via the Unbound API.

Each workflow chains AI â€œagentsâ€ together, validates outputs using configurable rules, retries on failure, and automatically passes context between steps.

Built for Unbound Hackathon (Feb 2026).

â¸»

ğŸš€ Key Highlights
	â€¢	Workflow Builder UI (HTML + CSS + JS)
	â€¢	Create, edit, delete workflows
	â€¢	Add & reorder steps
	â€¢	Configure model, prompt, criteria, retries, context mode
	â€¢	Agentic Execution Engine
	â€¢	Sequential LLM execution with retries
	â€¢	Context injection between steps
	â€¢	Background execution with live polling
	â€¢	Completion Criteria Engine
	â€¢	contains, regex, json_valid
	â€¢	Step-level pass/fail logic
	â€¢	Live Run Monitoring
	â€¢	Real-time status via polling
	â€¢	Step attempts, outputs, errors
	â€¢	Full execution history
	â€¢	Persistent Storage
	â€¢	SQLite + SQLAlchemy
	â€¢	Workflows, Steps, Runs, RunSteps

â¸»

ğŸ§± Tech Stack

Backend
	â€¢	FastAPI, SQLAlchemy, SQLite
	â€¢	Unbound LLM API
	â€¢	BackgroundTasks, httpx

Frontend
	â€¢	Vanilla HTML, CSS, JavaScript
	â€¢	Polling-based live updates (no WebSockets)

â¸»

ğŸ—ï¸ Architecture

Workflow â†’ Steps â†’ LLM Call â†’ Criteria Check â†’ Retry / Pass
                                    â†“
                              Context Injection


â¸»

ğŸ“Œ Example Use Case
	1.	Generate Python code
	2.	Validate output using regex
	3.	Pass code to next step
	4.	Auto-retry on failure
	5.	Track execution history

â¸»

ğŸ¯ What This Demonstrates
	â€¢	Agentic system design
	â€¢	LLM orchestration
	â€¢	Backend-frontend coordination
	â€¢	Reliability via retries & validation
	â€¢	Real-time execution monitoring

â¸»

ğŸ‘¤ Author

Pon Nigitha Varatharajan
Unbound Hackathon â€“ Feb 2026

â¸»

